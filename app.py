import streamlit as st
import os
import time
import glob
import cv2
import numpy as np
import pytesseract
from PIL import Image
from gtts import gTTS
from googletrans import Translator

# ğŸ’¾ Crear carpeta para audios temporales si no existe
try:
    os.mkdir("temp")
except:
    pass

# ğŸ§¼ Eliminar audios antiguos
def remove_files(n):
    mp3_files = glob.glob("temp/*mp3")
    if len(mp3_files) != 0:
        now = time.time()
        n_days = n * 86400
        for f in mp3_files:
            if os.stat(f).st_mtime < now - n_days:
                os.remove(f)

remove_files(7)

# ğŸ—£ï¸ FunciÃ³n de texto a voz
def text_to_speech(input_language, output_language, text, tld):
    translation = translator.translate(text, src=input_language, dest=output_language)
    trans_text = translation.text
    tts = gTTS(trans_text, lang=output_language, tld=tld, slow=False)
    try:
        my_file_name = text[0:20]
    except:
        my_file_name = "audio"
    tts.save(f"temp/{my_file_name}.mp3")
    return my_file_name, trans_text


# ğŸ€ DISEÃ‘O ESTÃ‰TICO LINDO
st.set_page_config(page_title="ğŸŒ¸ OCR MÃ¡gico de Audio", layout="centered", page_icon="ğŸ€")
st.markdown(
    """
    <style>
    body {
        background-color: #fff0f5;
    }
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stButton>button {
        background-color: #ffb6c1;
        color: white;
        border-radius: 10px;
        border: none;
        padding: 10px 20px;
        font-weight: bold;
    }
    .stTextInput>div>input {
        border-radius: 10px;
    }
    .stSidebar {
        background-color: #ffe4e1;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ğŸ€ ENCABEZADO
st.image("https://i.imgur.com/jWcqK4i.png", width=200)
st.title("ğŸ“âœ¨ OCR MÃ¡gico con Audio y TraducciÃ³n")
st.markdown(
    """
    Convierte imÃ¡genes con texto en audio traducido en segundos.  
    Ideal para ğŸ“š apuntes, ğŸ§¾ facturas, ğŸ“œ documentos y mÃ¡s.  
    Â¡Sube una imagen o toma una foto y escucha la magia! ğŸ§ğŸ’«
    """
)

# ğŸ“¸ FUENTE DE IMAGEN
st.markdown("### ğŸ“· Paso 1: Sube o toma una imagen")

cam_ = st.checkbox("ğŸ“¸ Usar cÃ¡mara")

if cam_:
    img_file_buffer = st.camera_input("Toma una foto con tu cÃ¡mara ğŸ“·")
else:
    img_file_buffer = None

bg_image = st.file_uploader("ğŸ“ Sube una imagen (JPG/PNG)", type=["png", "jpg", "jpeg"])
text = ""

# ğŸ“‹ PROCESAMIENTO DE IMAGEN
if bg_image is not None:
    uploaded_file = bg_image
    st.image(uploaded_file, caption='ğŸ–¼ï¸ Vista previa de la imagen', use_container_width=True)
    with open(uploaded_file.name, 'wb') as f:
        f.write(uploaded_file.read())
    st.success("âœ… Imagen cargada correctamente")
    img_cv = cv2.imread(f"{uploaded_file.name}")
    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
    text = pytesseract.image_to_string(img_rgb)
    st.markdown("### ğŸ” Texto detectado:")
    st.write(text)

# ğŸ“‹ Procesar imagen de cÃ¡mara si estÃ¡ habilitada
if img_file_buffer is not None:
    st.markdown("### ğŸï¸ Procesando foto tomada...")
    bytes_data = img_file_buffer.getvalue()
    cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)

    filtro = st.radio("ğŸ¨ Aplicar Filtro a la imagen", ('Con Filtro', 'Sin Filtro'))
    if filtro == 'Con Filtro':
        cv2_img = cv2.bitwise_not(cv2_img)

    img_rgb = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)
    text = pytesseract.image_to_string(img_rgb)
    st.markdown("### ğŸ” Texto detectado:")
    st.write(text)


# ğŸ”¤ PARÃMETROS DE TRADUCCIÃ“N Y AUDIO
st.markdown("### ğŸŒ Paso 2: Traduce y escucha tu texto")

with st.expander("ğŸšï¸ ParÃ¡metros de idioma y voz"):

    translator = Translator()

    in_lang = st.selectbox("ğŸŒ Idioma del texto detectado:", ("EspaÃ±ol", "InglÃ©s", "JaponÃ©s", "MandarÃ­n", "Coreano", "BengalÃ­"))
    out_lang = st.selectbox("ğŸ§ Idioma de salida para el audio:", ("EspaÃ±ol", "InglÃ©s", "JaponÃ©s", "MandarÃ­n", "Coreano", "BengalÃ­"))
    accent = st.selectbox("ğŸ™ï¸ Acento del audio (si aplica)", ("Default", "India", "United Kingdom", "United States", "Canada", "Australia", "Ireland", "South Africa"))

    lang_dict = {
        "EspaÃ±ol": "es", "InglÃ©s": "en", "JaponÃ©s": "ja", "MandarÃ­n": "zh-cn",
        "Coreano": "ko", "BengalÃ­": "bn"
    }

    tld_dict = {
        "Default": "com", "India": "co.in", "United Kingdom": "co.uk",
        "United States": "com", "Canada": "ca", "Australia": "com.au",
        "Ireland": "ie", "South Africa": "co.za"
    }

    input_language = lang_dict[in_lang]
    output_language = lang_dict[out_lang]
    tld = tld_dict[accent]

    show_text = st.checkbox("ğŸ“„ Mostrar texto traducido antes de reproducir")

# â–¶ï¸ BOTÃ“N PARA CONVERTIR
if st.button("âœ¨ Convertir a Audio"):
    if text.strip() == "":
        st.warning("âš ï¸ No se detectÃ³ texto para convertir.")
    else:
        result, output_text = text_to_speech(input_language, output_language, text, tld)
        audio_file = open(f"temp/{result}.mp3", "rb")
        audio_bytes = audio_file.read()
        st.success("âœ… Audio generado exitosamente")
        st.audio(audio_bytes, format="audio/mp3", start_time=0)

        if show_text:
            st.markdown("### ğŸ“œ Texto traducido:")
            st.write(output_text)

